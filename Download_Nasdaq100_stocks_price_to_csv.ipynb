{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# Pretend use browser\n",
    "headers = {'User-Agent': 'Mozilla/75.0 Chrome/80.0.3987.163 '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  stock symbol\n",
    "def save_nq100_symbols():\n",
    "    \n",
    "    # crawler websites\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/NASDAQ-100',headers = headers)\n",
    "\n",
    "    # source is text, parser is lxml\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    \n",
    "    # table\n",
    "    table = soup.find_all(\"table\",{\"id\" : \"constituents\"})[0]\n",
    "    \n",
    "    \n",
    "    symbols = []\n",
    "    \n",
    "    #tr is row of table\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        \n",
    "        # soup object get text)\n",
    "        symbol = row.findAll('td')[0].get_text(strip=True)\n",
    "\n",
    "        symbols.append(symbol)\n",
    "        \n",
    "    #  save result to pickle\n",
    "    with open(\"NQ100.pickle\",\"wb\") as file:\n",
    "        pickle.dump(symbols, file)\n",
    "    \n",
    "    return symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Activision Blizzard',\n",
       " 'Adobe Inc.',\n",
       " 'Advanced Micro Devices',\n",
       " 'Alexion Pharmaceuticals',\n",
       " 'Align Technology, Inc.',\n",
       " 'Alphabet Inc.(Class A)',\n",
       " 'Alphabet Inc.(Class C)',\n",
       " 'Amazon.com',\n",
       " 'American Airlines Group',\n",
       " 'Amgen Inc.',\n",
       " 'Analog Devices',\n",
       " 'ANSYS',\n",
       " 'Apple Inc.',\n",
       " 'Applied Materials, Inc.',\n",
       " 'ASML Holding',\n",
       " 'Autodesk, Inc.',\n",
       " 'Automatic Data Processing, Inc.',\n",
       " 'Baidu.com, Inc.',\n",
       " 'Biogen, Inc',\n",
       " 'BioMarin Pharmaceutical, Inc.',\n",
       " 'Booking Holdings',\n",
       " 'Broadcom Inc.',\n",
       " 'Cadence Design Systems',\n",
       " 'CDW',\n",
       " 'Cerner Corporation',\n",
       " 'Charter Communications, Inc.',\n",
       " 'Check Point Software Technologies Ltd.',\n",
       " 'Cintas Corporation',\n",
       " 'Cisco Systems',\n",
       " 'Citrix Systems',\n",
       " 'Cognizant Technology Solutions Corporation',\n",
       " 'Comcast Corporation',\n",
       " 'Copart',\n",
       " 'CoStar Group',\n",
       " 'Costco Wholesale Corporation',\n",
       " 'CSX Corporation',\n",
       " 'Dollar Tree, Inc.',\n",
       " 'eBay Inc.',\n",
       " 'Electronic Arts',\n",
       " 'Exelon Corporation',\n",
       " 'Expedia Group',\n",
       " 'Facebook, Inc.',\n",
       " 'Fastenal Company',\n",
       " 'Fiserv, Inc.',\n",
       " 'Fox Corporation(Class A)',\n",
       " 'Fox Corporation(Class B)',\n",
       " 'Gilead Sciences, Inc.',\n",
       " 'IDEXX Laboratories',\n",
       " 'Illumina, Inc.',\n",
       " 'Incyte Corporation',\n",
       " 'Intel Corporation',\n",
       " 'Intuit, Inc.',\n",
       " 'Intuitive Surgical Inc.',\n",
       " 'JD.com',\n",
       " 'KLA Corporation',\n",
       " 'Kraft Heinz',\n",
       " 'Lam Research, Inc.',\n",
       " 'Liberty Global(Class A)',\n",
       " 'Liberty Global(Class C)',\n",
       " 'Lululemon athletica',\n",
       " 'Marriott International, Inc.',\n",
       " 'Maxim Integrated Products',\n",
       " 'MercadoLibre',\n",
       " 'Microchip Technology',\n",
       " 'Micron Technology, Inc.',\n",
       " 'Microsoft Corporation',\n",
       " 'MondelÄ“z International',\n",
       " 'Monster Beverage Corporation',\n",
       " 'NetApp',\n",
       " 'NetEase, Inc.',\n",
       " 'Netflix',\n",
       " 'NVIDIA Corporation',\n",
       " 'NXP Semiconductors N.V.',\n",
       " \"O'Reilly Automotive, Inc.\",\n",
       " 'PACCAR Inc.',\n",
       " 'Paychex, Inc.',\n",
       " 'PayPal Holdings, Inc.',\n",
       " 'PepsiCo, Inc.',\n",
       " 'QUALCOMM Incorporated',\n",
       " 'Regeneron Pharmaceuticals',\n",
       " 'Ross Stores Inc.',\n",
       " 'Seattle Genetics',\n",
       " 'Sirius XM Radio, Inc.',\n",
       " 'Skyworks Solutions, Inc.',\n",
       " 'Splunk',\n",
       " 'Starbucks Corporation',\n",
       " 'Synopsys, Inc.',\n",
       " 'T-Mobile US',\n",
       " 'Take-Two Interactive, Inc.',\n",
       " 'Tesla, Inc.',\n",
       " 'Texas Instruments, Inc.',\n",
       " 'Trip.com Group',\n",
       " 'Ulta Beauty',\n",
       " 'United Airlines Holdings',\n",
       " 'VeriSign',\n",
       " 'Verisk Analytics',\n",
       " 'Vertex Pharmaceuticals',\n",
       " 'Walgreen Boots Alliance, Inc.',\n",
       " 'Workday, Inc.',\n",
       " 'Western Digital',\n",
       " 'Willis Towers Watson',\n",
       " 'Xcel Energy, Inc.',\n",
       " 'Xilinx, Inc.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_nq100_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save price from spider\n",
    "def get_data_from_datareader(beg_y, beg_m, beg_d, end_y, end_m, end_d, reload_symbols=False):\n",
    "\n",
    "    # if reload, execute save_nq100_symbols()\n",
    "    if reload_symbols:\n",
    "        symbols = save_nq100_symbols()\n",
    "    # if no reload, read NQ100.pickle     \n",
    "    else:\n",
    "        with open(\"NQ100.pickle\",\"rb\") as file:\n",
    "            symbols = pickle.load(file)\n",
    "    \n",
    "    # if no folder exist, mkdir\n",
    "    if not os.path.exists('NQ100'):\n",
    "        os.makedirs('NQ100')\n",
    "        \n",
    "    beg = dt.datetime(beg_y, beg_m, beg_d)\n",
    "    end = dt.datetime(end_y, end_m, end_d)\n",
    "#     print(beg,end)\n",
    "\n",
    "    #for loop price from 'stooq'\n",
    "    for symbol in symbols:\n",
    "        #try: check symbol is downloaed\n",
    "        try:\n",
    "            if not os.path.exists('NQ100/{}.csv'.format(symbol)):\n",
    "                df = web.DataReader(symbol, 'stooq', beg, end)\n",
    "                df.to_csv('NQ100/{}.csv'.format(symbol))\n",
    "            else:\n",
    "                print('already have {}'.format(symbol))\n",
    "        # except\n",
    "        except:\n",
    "            print(symbol + \"can not download\")\n",
    "    print(\"crawler done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawler done\n"
     ]
    }
   ],
   "source": [
    "get_data_from_datareader(2020,1,1,2020,4,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
